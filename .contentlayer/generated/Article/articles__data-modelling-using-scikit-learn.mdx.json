{
  "title": "Data Modelling classification problem - Part 1",
  "publishedAt": "Mar 18, 2023",
  "description": "How can you train the model in data analytics with three different machine learning algorithm",
  "seoDescription": "This is the seoDescription for this markdown file.",
  "categories": [
    {
      "title": "Data Analytics",
      "type": "Categories",
      "_raw": {}
    }
  ],
  "tags": [
    {
      "title": "pandas",
      "type": "Tag",
      "_raw": {}
    },
    {
      "title": "matplotlib",
      "type": "Tag",
      "_raw": {}
    }
  ],
  "author": {
    "name": "Vo Thanh Luan",
    "image": "https://imgur.com/wnuKAT5.jpg",
    "type": "Author",
    "_raw": {}
  },
  "image": "https://i.imgur.com/uAurwRT.png'",
  "body": {
    "raw": "\n## Introduction\n\nIn the field of machine learning, classification is a widely used technique that involves categorizing data into predefined classes or categories. This technique is commonly used in various applications such as image recognition, spam filtering, fraud detection, and sentiment analysis.\n\nIn a classification problem, the machine learning algorithm is trained to predict the class or category of a given input based on its features. For instance, a spam filtering algorithm might classify an email as spam or not spam based on the presence or absence of certain keywords.\n\nHowever, before we can start building a classification model, we need to first identify whether the problem we are trying to solve is a classification problem or not. In this blog, we will explore the characteristics of classification problems and learn how to detect them. We will also discuss some common techniques that are used to solve classification problems, and how they can be applied in various real-world scenarios.\n\nWhether you are a beginner or an experienced data scientist, this blog will provide you with a solid understanding of classification problems and equip you with the skills to detect and solve them effectively. So, let's dive in!\n\n## Problem statement\n\nFor this tutorial, I will be using the dataset from The Johns Hopkins University which the target is to predict the likelihood of sepsis in ICU patients.\n\nThis dataset will be as following table\n| Column Name | Attribute/Target | Description |\n|------------------------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ID | N/A | Unique number to represent patient ID |\n| PRG | Attribute1 | Plasma glucose\n|\n| PL | Attribute 2 | Blood Work Result-1 (mu U/ml) |\n| PR | Attribute 3 | Blood Pressure (mm Hg)\n|\n| SK | Attribute 4 | Blood Work Result-2 (mm)\n|\n| TS | Attribute 5 | Blood Work Result-3 (mu U/ml)\n|\n| M11 | Attribute 6 | Body mass index (weight in kg/(height in m)^2\n|\n| BD2 | Attribute 7 | Blood Work Result-4 (mu U/ml) |\n| Age | Attribute 8 | patients age (years) |\n| Insurance | N/A | If a patient holds a valid insurance card\n|\n| Sepssis | Target | Positive: if a patient in ICU will develop a sepsis , and Negative: otherwise |\n\nThe target column that I will predict is the Sepssis which has two possible value: Positive if the patient will develop a sepsis, and Negative if they will not have sepssis\n\nFirst thing first, we need to load the data then do some Exploratory Data Analysis (EDA), if you are not familiar with EDA, here is some definition of its:\n\n- <b>Exploratory Data Analysis (EDA) </b> is the process of examining and analyzing\n  data to extract insights, identify patterns, and understand the underlying structure\n  of the data. EDA is typically the first step in any data analysis process and is\n  performed before building predictive models or making any inferences from the data.\n\nThe reason why we need to do EDA is to gain a deeper understanding of the data and its properties, which can help identify any issues or anomalies that may be present in the data. EDA can also help identify the relationship between the different variables and the target variable and can help in feature selection for predictive modeling.\n\n## Data retrieving\n\nAt the first step, we will need to load the data, in this case, the data will be in .csv format\n\n```python\n# Load the data train file into a dataframe called \"train_df\"\ntrain_df = pd.read_csv(\"Paitients_Files_Train.csv\")\n\n# Load the data test file into a dataframe called \"test_df\"\ntest_df = pd.read_csv(\"Paitients_Files_Test.csv\")\n```\n\nHowever, we will need to install some necessary packages first, then let install and import them in the notebook\n\n```python\n# pip3 install matplotlib pandas seaborn scikit_learn numpy\n```\n\n```python\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport pickle as pkl\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import *\n```\n\nLet through of them and see how can they be used in this notebook\n\n- os: Used to interact with the operating system, such as setting working directories or listing files in a directory.\n\n- pandas: Used to work with data frames, which are a table-like data structure in Python. Pandas provides tools for data manipulation, cleaning, and analysis.\n\n- matplotlib.pyplot: A plotting library used for creating data visualizations in Python. It provides various functions to create different types of plots, such as line plots, scatter plots, and histograms.\n\n- numpy: A fundamental package for scientific computing in Python. It provides support for large, multi-dimensional arrays and matrices, as well as a large collection of mathematical functions to operate on these arrays.\n\n- seaborn: A data visualization library built on top of matplotlib. It provides a high-level interface for creating informative and attractive statistical graphics.\n\n- pickle: A module used for object serialization and deserialization in Python. It allows for the efficient storage and retrieval of Python objects.\n\n- LabelEncoder: A class from the scikit-learn library used to convert categorical variables into numerical labels.\n\n- LogisticRegression: A class from scikit-learn used to fit logistic regression models for binary classification.\n\n- LogisticRegressionCV: A class from scikit-learn used to perform logistic regression with cross-validation.\n\n- DecisionTreeClassifier: A class from scikit-learn used to fit decision tree models for classification.\n\n- RandomForestClassifier: A class from scikit-learn used to fit random forest models for classification.\n\n- train_test_split: A function from scikit-learn used to split data into training and testing sets.\n\n- GridSearchCV: A class from scikit-learn used for hyperparameter tuning by searching over specified parameter values for an estimator.\n\n- ElasticNet: A class from scikit-learn used to fit linear regression models with both L1 and L2 regularization.\n\n- metrics: A module from scikit-learn containing various metrics used to evaluate model performance, such as accuracy, precision, recall, and F1 score.\n\nThen, let see the dataframe of each dataset\n\n```python\n# view first 5 rows of train dataframe\ntrain_df.head()\n```\n\n| Index | ID        | PRG | PL  | PR | SK | TS  | M11  | BD2   | Age | Insurance | Sepssis  |\n|-------|-----------|-----|-----|----|----|-----|------|-------|-----|-----------|----------|\n| 0     | ICU200010 | 6   | 148 | 72 | 35 | 0   | 33.6 | 0.627 | 50  | 0         | Positive |\n| 1     | ICU200011 | 1   | 85  | 66 | 29 | 0   | 26.6 | 0.351 | 31  | 0         | Negative |\n| 2     | ICU200012 | 8   | 183 | 64 | 0  | 0   | 23.3 | 0.672 | 32  | 1         | Positive |\n| 3     | ICU200013 | 1   | 89  | 66 | 23 | 94  | 28.1 | 0.167 | 21  | 1         | Negative |\n| 4     | ICU200014 | 0   | 137 | 40 | 35 | 168 | 43.1 | 2.288 | 33  | 1         | Positive |\n\n```python\n# view first 5 rows of test dataframe\ntest_df.head()\n```\n\n| Index | ID        | PRG | PL  | PR  | SK  | TS  | M11  | BD2   | Age | Insurance |\n| ----- | --------- | --- | --- | --- | --- | --- | ---- | ----- | --- | --------- |\n| 0     | ICU200609 | 1   | 109 | 38  | 18  | 120 | 23.1 | 0.407 | 26  | 1         |\n| 1     | ICU200610 | 1   | 108 | 88  | 19  | 0   | 27.1 | 0.400 | 24  | 1         |\n| 2     | ICU200611 | 6   | 96  | 0   | 0   | 0   | 23.7 | 0.190 | 28  | 1         |\n| 3     | ICU200612 | 1   | 124 | 74  | 36  | 0   | 27.8 | 0.100 | 30  | 1         |\n| 4     | ICU200613 | 7   | 150 | 78  | 29  | 126 | 35.2 | 0.692 | 54  | 0         |\n\nThe test_df which will be used to evaluate the performance of the model we trained. Since we want to predict the \"Sepssis\" column using the other input variables, we do not see this column in the test_df. Instead, we use the input variables in test_df to make predictions for the \"Sepssis\" column, and then compare these predictions to the actual values in the testing set to evaluate the accuracy of our model.\n\n```python\n# check the training dataset columns and their datatypes\ntrain_df.info()\n```\n\n| #   | Column    | Non-Null Count | Dtype   |\n| --- | --------- | -------------- | ------- |\n| 0   | ID        | 169 non-null   | object  |\n| 1   | PRG       | 169 non-null   | int64   |\n| 2   | PL        | 169 non-null   | int64   |\n| 3   | PR        | 169 non-null   | int64   |\n| 4   | SK        | 169 non-null   | int64   |\n| 5   | TS        | 169 non-null   | int64   |\n| 6   | M11       | 169 non-null   | float64 |\n| 7   | BD2       | 169 non-null   | float64 |\n| 8   | Age       | 169 non-null   | int64   |\n| 9   | Insurance | 169 non-null   | int64   |\n\n```python\n# check the testing dataset columns and their datatypes\ntest_df.info()\n```\n\n| #   | Column | Non-Null Count | Dtype   |\n| --- | ------ | -------------- | ------- |\n| 0   | ID     | 169 non-null   | object  |\n| 1   | PRG    | 169 non-null   | int64   |\n| 2   | PL     | 169 non-null   | int64   |\n| 3   | PR     | 169 non-null   | int64   |\n| 4   | SK     | 169 non-null   | int64   |\n| 5   | TS     | 169 non-null   | int64   |\n| 6   | M11    | 169 non-null   | float64 |\n| 7   | BD2    | 169 non-null   | float64 |\n| 8   | Age    | 169 non-null   | int64   |\n\nAs we can see, there are no columns in either the training or testing dataset that have missing values, which means we won't need to deal with any null values during data cleaning.\n\nAdditionally, the data types for the columns in both datasets appear to be correct, with integer columns being represented as int64 and floating-point columns as float64.\n\nTwo columns, ID and Sepssis, are represented as object data type since they contain string values. However, ID is unnecessary and will be removed, while Sepssis will be encoded later on.\n\n```python\ntrain_df.describe().T\n```\n\n|           | count | mean       | std        | min    | 25%    | 50%     | 75%     | max    |\n| --------- | ----- | ---------- | ---------- | ------ | ------ | ------- | ------- | ------ |\n| PRG       | 599.0 | 3.824708   | 3.362839   | 0.000  | 1.000  | 3.000   | 6.000   | 17.00  |\n| PL        | 599.0 | 120.153589 | 32.682364  | 0.000  | 99.000 | 116.000 | 140.000 | 198.00 |\n| PR        | 599.0 | 68.732888  | 19.335675  | 0.000  | 64.000 | 70.000  | 80.000  | 122.00 |\n| SK        | 599.0 | 20.562604  | 16.017622  | 0.000  | 0.000  | 23.000  | 32.000  | 99.00  |\n| TS        | 599.0 | 79.460768  | 116.576176 | 0.000  | 0.000  | 36.000  | 123.500 | 846.00 |\n| M11       | 599.0 | 31.920033  | 8.008227   | 0.000  | 27.100 | 32.000  | 36.550  | 67.10  |\n| BD2       | 599.0 | 0.481187   | 0.337552   | 0.078  | 0.248  | 0.383   | 0.647   | 2.42   |\n| Age       | 599.0 | 33.290484  | 11.828446  | 21.000 | 24.000 | 29.000  | 40.000  | 81.00  |\n| Insurance | 599.0 | 0.686144   | 0.464447   | 0.000  | 0.000  | 1.000   | 1.000   | 1.00   |\n\nBased on the summary of statistics provided, we can draw some conclusions about the columns and their values\n\n- There are 599 observations in each column, which indicates that there are no missing values in the dataset.\n- Most columns, the average and median values are similar, suggesting that their distribution is similar to that of a normal distribution.\n- The Insurance columns contains nominal data and other columns contain either discrete or continuous data.\n- Blood Work Result-3 (TS) has a mean of 79.46 and a large standard deviation of 116.58. This attribute has a positively skewed distribution toward\n  higher number, with most patients having low results and a few patients having very high results.\n- The patient ages range from 21 to 81 years, with a mean age of 33.29 and a standard deviation of 11.83. This indicates that the patient population is\n  relatively young, with most patients being in their 20s or 30s.\n- Most patients (68.6%) hold a valid insurance card, as indicated by the Insurance column.\n\n```python\n# visualize the value distribution of the dataframe\ntrain_df.hist(figsize=(20, 10))\nplt.show()\n```\n\nThe graph above confirms some observations made earlier about the distribution of the variables in the dataset. For instance, the histograms for the PL, PR,\nand M11 columns are roughly symmetric and resemble a normal distribution curve. This suggests that these variables are normally distributed.\n\nOn the other hand, the histogram for the TS column shows a long right tail, indicating that the distribution is highly skewed to the right. This\ncorresponds to the high skewness value observed in the statistical summary. Similarly, the PRG, SK, BD2, and Age columns also exhibit some degree of\nskewness.\n\nIt is important to note that skewed distributions can affect the performance of certain statistical analyses and machine learning models. Therefore, we\nmay need to consider normalizing or transforming these variables before applying certain techniques or models.\n\n## That's all for now\n\nIn part 1 of this series, we focused on retrieving the dataset and importing the necessary packages for data cleaning, exploratory data analysis (EDA), and machine learning. The dataset was described in terms of its data fields, and attributes/targets, and then loaded into the notebook.\n\nIt is essential to note that while data retrieval is a crucial part of the machine learning workflow, it is only the beginning. The next steps are data cleaning and exploratory data analysis, which are crucial in preparing the dataset for machine learning.\n\nData cleaning is a process of identifying and addressing issues in the data that could affect the accuracy of the model. These issues include missing values, outliers, duplicates, and inconsistent data. In part 2 of this series, we will focus on data cleaning by identifying and addressing these issues.\n",
    "code": "var Component=(()=>{var o=Object.create;var d=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),k=(i,e)=>{for(var t in e)d(i,t,{get:e[t],enumerable:!0})},a=(i,e,t,r)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let l of p(e))!g.call(i,l)&&l!==t&&d(i,l,{get:()=>e[l],enumerable:!(r=m(e,l))||r.enumerable});return i};var b=(i,e,t)=>(t=i!=null?o(u(i)):{},a(e||!i||!i.__esModule?d(t,\"default\",{value:i,enumerable:!0}):t,i)),N=i=>a(d({},\"__esModule\",{value:!0}),i);var s=f((T,c)=>{c.exports=_jsx_runtime});var A={};k(A,{default:()=>v,frontmatter:()=>y});var n=b(s()),y={title:\"Data Modelling classification problem - Part 1\",publishedAt:\"2023-03-18\",description:\"How can you train the model in data analytics with three different machine learning algorithm\",categories:[{title:\"Data Analytics\"}],tags:[{title:\"pandas\"},{title:\"matplotlib\"}],seoDescription:\"This is the seoDescription for this markdown file.\",author:{name:\"Vo Thanh Luan\",image:\"https://imgur.com/wnuKAT5.jpg\"},image:\"https://i.imgur.com/uAurwRT.png'\"};function h(i){let e=Object.assign({div:\"div\",p:\"p\",ol:\"ol\",li:\"li\",a:\"a\",h2:\"h2\",span:\"span\",table:\"table\",thead:\"thead\",tr:\"tr\",th:\"th\",tbody:\"tbody\",td:\"td\",ul:\"ul\",pre:\"pre\",code:\"code\"},i.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.div,{className:\"toc\",children:[(0,n.jsx)(e.p,{className:\"ml-6 pt-2 pb-2 text-xl font-bold\",children:\"Table of Contents\"}),(0,n.jsxs)(e.ol,{className:\"toc-level toc-level-1\",children:[(0,n.jsx)(e.li,{className:\"toc-item toc-item-h2\",children:(0,n.jsx)(e.a,{className:\"toc-link toc-link-h2\",href:\"#introduction\",children:\"Introduction\"})}),(0,n.jsx)(e.li,{className:\"toc-item toc-item-h2\",children:(0,n.jsx)(e.a,{className:\"toc-link toc-link-h2\",href:\"#problem-statement\",children:\"Problem statement\"})}),(0,n.jsx)(e.li,{className:\"toc-item toc-item-h2\",children:(0,n.jsx)(e.a,{className:\"toc-link toc-link-h2\",href:\"#data-retrieving\",children:\"Data retrieving\"})}),(0,n.jsx)(e.li,{className:\"toc-item toc-item-h2\",children:(0,n.jsx)(e.a,{className:\"toc-link toc-link-h2\",href:\"#thats-all-for-now\",children:\"That's all for now\"})})]})]}),`\n`,(0,n.jsxs)(e.h2,{id:\"introduction\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#introduction\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Introduction\"]}),`\n`,(0,n.jsx)(e.p,{children:\"In the field of machine learning, classification is a widely used technique that involves categorizing data into predefined classes or categories. This technique is commonly used in various applications such as image recognition, spam filtering, fraud detection, and sentiment analysis.\"}),`\n`,(0,n.jsx)(e.p,{children:\"In a classification problem, the machine learning algorithm is trained to predict the class or category of a given input based on its features. For instance, a spam filtering algorithm might classify an email as spam or not spam based on the presence or absence of certain keywords.\"}),`\n`,(0,n.jsx)(e.p,{children:\"However, before we can start building a classification model, we need to first identify whether the problem we are trying to solve is a classification problem or not. In this blog, we will explore the characteristics of classification problems and learn how to detect them. We will also discuss some common techniques that are used to solve classification problems, and how they can be applied in various real-world scenarios.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Whether you are a beginner or an experienced data scientist, this blog will provide you with a solid understanding of classification problems and equip you with the skills to detect and solve them effectively. So, let's dive in!\"}),`\n`,(0,n.jsxs)(e.h2,{id:\"problem-statement\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#problem-statement\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Problem statement\"]}),`\n`,(0,n.jsx)(e.p,{children:\"For this tutorial, I will be using the dataset from The Johns Hopkins University which the target is to predict the likelihood of sepsis in ICU patients.\"}),`\n`,(0,n.jsx)(e.p,{children:\"This dataset will be as following table\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Column Name\"}),(0,n.jsx)(e.th,{children:\"Attribute/Target\"}),(0,n.jsx)(e.th,{children:\"Description\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"ID\"}),(0,n.jsx)(e.td,{children:\"N/A\"}),(0,n.jsx)(e.td,{children:\"Unique number to represent patient ID\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"PRG\"}),(0,n.jsx)(e.td,{children:\"Attribute1\"}),(0,n.jsx)(e.td,{children:\"Plasma glucose\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"PL\"}),(0,n.jsx)(e.td,{children:\"Attribute 2\"}),(0,n.jsx)(e.td,{children:\"Blood Work Result-1 (mu U/ml)\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"PR\"}),(0,n.jsx)(e.td,{children:\"Attribute 3\"}),(0,n.jsx)(e.td,{children:\"Blood Pressure (mm Hg)\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SK\"}),(0,n.jsx)(e.td,{children:\"Attribute 4\"}),(0,n.jsx)(e.td,{children:\"Blood Work Result-2 (mm)\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"TS\"}),(0,n.jsx)(e.td,{children:\"Attribute 5\"}),(0,n.jsx)(e.td,{children:\"Blood Work Result-3 (mu U/ml)\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"M11\"}),(0,n.jsx)(e.td,{children:\"Attribute 6\"}),(0,n.jsx)(e.td,{children:\"Body mass index (weight in kg/(height in m)^2\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"BD2\"}),(0,n.jsx)(e.td,{children:\"Attribute 7\"}),(0,n.jsx)(e.td,{children:\"Blood Work Result-4 (mu U/ml)\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Age\"}),(0,n.jsx)(e.td,{children:\"Attribute 8\"}),(0,n.jsx)(e.td,{children:\"patients age (years)\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Insurance\"}),(0,n.jsx)(e.td,{children:\"N/A\"}),(0,n.jsx)(e.td,{children:\"If a patient holds a valid insurance card\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{}),(0,n.jsx)(e.td,{})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Sepssis\"}),(0,n.jsx)(e.td,{children:\"Target\"}),(0,n.jsx)(e.td,{children:\"Positive: if a patient in ICU will develop a sepsis , and Negative: otherwise\"})]})]})]}),`\n`,(0,n.jsx)(e.p,{children:\"The target column that I will predict is the Sepssis which has two possible value: Positive if the patient will develop a sepsis, and Negative if they will not have sepssis\"}),`\n`,(0,n.jsx)(e.p,{children:\"First thing first, we need to load the data then do some Exploratory Data Analysis (EDA), if you are not familiar with EDA, here is some definition of its:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(\"b\",{children:\"Exploratory Data Analysis (EDA) \"}),` is the process of examining and analyzing\ndata to extract insights, identify patterns, and understand the underlying structure\nof the data. EDA is typically the first step in any data analysis process and is\nperformed before building predictive models or making any inferences from the data.`]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"The reason why we need to do EDA is to gain a deeper understanding of the data and its properties, which can help identify any issues or anomalies that may be present in the data. EDA can also help identify the relationship between the different variables and the target variable and can help in feature selection for predictive modeling.\"}),`\n`,(0,n.jsxs)(e.h2,{id:\"data-retrieving\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#data-retrieving\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Data retrieving\"]}),`\n`,(0,n.jsx)(e.p,{children:\"At the first step, we will need to load the data, in this case, the data will be in .csv format\"}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsxs)(e.code,{className:\"language-python code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:'# Load the data train file into a dataframe called \"train_df\"'}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"2\",children:[\"train_df \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" pd\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"read_csv\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token string\",children:'\"Paitients_Files_Train.csv\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line line-number\",line:\"3\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"4\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:'# Load the data test file into a dataframe called \"test_df\"'}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"5\",children:[\"test_df \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" pd\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"read_csv\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token string\",children:'\"Paitients_Files_Test.csv\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsx)(e.p,{children:\"However, we will need to install some necessary packages first, then let install and import them in the notebook\"}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsx)(e.code,{className:\"language-python code-highlight\",children:(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"# pip3 install matplotlib pandas seaborn scikit_learn numpy\"}),`\n`]})})}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsxs)(e.code,{className:\"language-python code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),` os\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"2\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" pandas \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"as\"}),` pd\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"3\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" matplotlib\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"pyplot \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"as\"}),` plt\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"4\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" numpy \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"as\"}),` np\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"5\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" seaborn \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"as\"}),` sns\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"6\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" pickle \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"as\"}),` pkl\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"7\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" sklearn\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"preprocessing \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),` LabelEncoder\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"8\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" sklearn\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"linear_model \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" LogisticRegression\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),` LogisticRegressionCV\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"9\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" sklearn\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"tree \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),` DecisionTreeClassifier\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"10\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" sklearn\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"ensemble \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),` RandomForestClassifier\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"11\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" sklearn\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"model_selection \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" train_test_split\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),` GridSearchCV\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"12\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" sklearn\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"linear_model \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),` ElasticNet\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"13\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" sklearn\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"metrics \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"*\"}),`\n`]})]})}),`\n`,(0,n.jsx)(e.p,{children:\"Let through of them and see how can they be used in this notebook\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"os: Used to interact with the operating system, such as setting working directories or listing files in a directory.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"pandas: Used to work with data frames, which are a table-like data structure in Python. Pandas provides tools for data manipulation, cleaning, and analysis.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"matplotlib.pyplot: A plotting library used for creating data visualizations in Python. It provides various functions to create different types of plots, such as line plots, scatter plots, and histograms.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"numpy: A fundamental package for scientific computing in Python. It provides support for large, multi-dimensional arrays and matrices, as well as a large collection of mathematical functions to operate on these arrays.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"seaborn: A data visualization library built on top of matplotlib. It provides a high-level interface for creating informative and attractive statistical graphics.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"pickle: A module used for object serialization and deserialization in Python. It allows for the efficient storage and retrieval of Python objects.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"LabelEncoder: A class from the scikit-learn library used to convert categorical variables into numerical labels.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"LogisticRegression: A class from scikit-learn used to fit logistic regression models for binary classification.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"LogisticRegressionCV: A class from scikit-learn used to perform logistic regression with cross-validation.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"DecisionTreeClassifier: A class from scikit-learn used to fit decision tree models for classification.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"RandomForestClassifier: A class from scikit-learn used to fit random forest models for classification.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"train_test_split: A function from scikit-learn used to split data into training and testing sets.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"GridSearchCV: A class from scikit-learn used for hyperparameter tuning by searching over specified parameter values for an estimator.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"ElasticNet: A class from scikit-learn used to fit linear regression models with both L1 and L2 regularization.\"}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"metrics: A module from scikit-learn containing various metrics used to evaluate model performance, such as accuracy, precision, recall, and F1 score.\"}),`\n`]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Then, let see the dataframe of each dataset\"}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsxs)(e.code,{className:\"language-python code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"# view first 5 rows of train dataframe\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"2\",children:[\"train_df\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"head\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Index\"}),(0,n.jsx)(e.th,{children:\"ID\"}),(0,n.jsx)(e.th,{children:\"PRG\"}),(0,n.jsx)(e.th,{children:\"PL\"}),(0,n.jsx)(e.th,{children:\"PR\"}),(0,n.jsx)(e.th,{children:\"SK\"}),(0,n.jsx)(e.th,{children:\"TS\"}),(0,n.jsx)(e.th,{children:\"M11\"}),(0,n.jsx)(e.th,{children:\"BD2\"}),(0,n.jsx)(e.th,{children:\"Age\"}),(0,n.jsx)(e.th,{children:\"Insurance\"}),(0,n.jsx)(e.th,{children:\"Sepssis\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"ICU200010\"}),(0,n.jsx)(e.td,{children:\"6\"}),(0,n.jsx)(e.td,{children:\"148\"}),(0,n.jsx)(e.td,{children:\"72\"}),(0,n.jsx)(e.td,{children:\"35\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"33.6\"}),(0,n.jsx)(e.td,{children:\"0.627\"}),(0,n.jsx)(e.td,{children:\"50\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"Positive\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"ICU200011\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"85\"}),(0,n.jsx)(e.td,{children:\"66\"}),(0,n.jsx)(e.td,{children:\"29\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"26.6\"}),(0,n.jsx)(e.td,{children:\"0.351\"}),(0,n.jsx)(e.td,{children:\"31\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"Negative\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"2\"}),(0,n.jsx)(e.td,{children:\"ICU200012\"}),(0,n.jsx)(e.td,{children:\"8\"}),(0,n.jsx)(e.td,{children:\"183\"}),(0,n.jsx)(e.td,{children:\"64\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"23.3\"}),(0,n.jsx)(e.td,{children:\"0.672\"}),(0,n.jsx)(e.td,{children:\"32\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"Positive\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"3\"}),(0,n.jsx)(e.td,{children:\"ICU200013\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"89\"}),(0,n.jsx)(e.td,{children:\"66\"}),(0,n.jsx)(e.td,{children:\"23\"}),(0,n.jsx)(e.td,{children:\"94\"}),(0,n.jsx)(e.td,{children:\"28.1\"}),(0,n.jsx)(e.td,{children:\"0.167\"}),(0,n.jsx)(e.td,{children:\"21\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"Negative\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"4\"}),(0,n.jsx)(e.td,{children:\"ICU200014\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"137\"}),(0,n.jsx)(e.td,{children:\"40\"}),(0,n.jsx)(e.td,{children:\"35\"}),(0,n.jsx)(e.td,{children:\"168\"}),(0,n.jsx)(e.td,{children:\"43.1\"}),(0,n.jsx)(e.td,{children:\"2.288\"}),(0,n.jsx)(e.td,{children:\"33\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"Positive\"})]})]})]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsxs)(e.code,{className:\"language-python code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"# view first 5 rows of test dataframe\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"2\",children:[\"test_df\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"head\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Index\"}),(0,n.jsx)(e.th,{children:\"ID\"}),(0,n.jsx)(e.th,{children:\"PRG\"}),(0,n.jsx)(e.th,{children:\"PL\"}),(0,n.jsx)(e.th,{children:\"PR\"}),(0,n.jsx)(e.th,{children:\"SK\"}),(0,n.jsx)(e.th,{children:\"TS\"}),(0,n.jsx)(e.th,{children:\"M11\"}),(0,n.jsx)(e.th,{children:\"BD2\"}),(0,n.jsx)(e.th,{children:\"Age\"}),(0,n.jsx)(e.th,{children:\"Insurance\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"ICU200609\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"109\"}),(0,n.jsx)(e.td,{children:\"38\"}),(0,n.jsx)(e.td,{children:\"18\"}),(0,n.jsx)(e.td,{children:\"120\"}),(0,n.jsx)(e.td,{children:\"23.1\"}),(0,n.jsx)(e.td,{children:\"0.407\"}),(0,n.jsx)(e.td,{children:\"26\"}),(0,n.jsx)(e.td,{children:\"1\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"ICU200610\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"108\"}),(0,n.jsx)(e.td,{children:\"88\"}),(0,n.jsx)(e.td,{children:\"19\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"27.1\"}),(0,n.jsx)(e.td,{children:\"0.400\"}),(0,n.jsx)(e.td,{children:\"24\"}),(0,n.jsx)(e.td,{children:\"1\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"2\"}),(0,n.jsx)(e.td,{children:\"ICU200611\"}),(0,n.jsx)(e.td,{children:\"6\"}),(0,n.jsx)(e.td,{children:\"96\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"23.7\"}),(0,n.jsx)(e.td,{children:\"0.190\"}),(0,n.jsx)(e.td,{children:\"28\"}),(0,n.jsx)(e.td,{children:\"1\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"3\"}),(0,n.jsx)(e.td,{children:\"ICU200612\"}),(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"124\"}),(0,n.jsx)(e.td,{children:\"74\"}),(0,n.jsx)(e.td,{children:\"36\"}),(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"27.8\"}),(0,n.jsx)(e.td,{children:\"0.100\"}),(0,n.jsx)(e.td,{children:\"30\"}),(0,n.jsx)(e.td,{children:\"1\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"4\"}),(0,n.jsx)(e.td,{children:\"ICU200613\"}),(0,n.jsx)(e.td,{children:\"7\"}),(0,n.jsx)(e.td,{children:\"150\"}),(0,n.jsx)(e.td,{children:\"78\"}),(0,n.jsx)(e.td,{children:\"29\"}),(0,n.jsx)(e.td,{children:\"126\"}),(0,n.jsx)(e.td,{children:\"35.2\"}),(0,n.jsx)(e.td,{children:\"0.692\"}),(0,n.jsx)(e.td,{children:\"54\"}),(0,n.jsx)(e.td,{children:\"0\"})]})]})]}),`\n`,(0,n.jsx)(e.p,{children:'The test_df which will be used to evaluate the performance of the model we trained. Since we want to predict the \"Sepssis\" column using the other input variables, we do not see this column in the test_df. Instead, we use the input variables in test_df to make predictions for the \"Sepssis\" column, and then compare these predictions to the actual values in the testing set to evaluate the accuracy of our model.'}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsxs)(e.code,{className:\"language-python code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"# check the training dataset columns and their datatypes\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"2\",children:[\"train_df\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"info\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"#\"}),(0,n.jsx)(e.th,{children:\"Column\"}),(0,n.jsx)(e.th,{children:\"Non-Null Count\"}),(0,n.jsx)(e.th,{children:\"Dtype\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"ID\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"object\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"PRG\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"2\"}),(0,n.jsx)(e.td,{children:\"PL\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"3\"}),(0,n.jsx)(e.td,{children:\"PR\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"4\"}),(0,n.jsx)(e.td,{children:\"SK\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"5\"}),(0,n.jsx)(e.td,{children:\"TS\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"6\"}),(0,n.jsx)(e.td,{children:\"M11\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"float64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"7\"}),(0,n.jsx)(e.td,{children:\"BD2\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"float64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"8\"}),(0,n.jsx)(e.td,{children:\"Age\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"9\"}),(0,n.jsx)(e.td,{children:\"Insurance\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]})]})]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsxs)(e.code,{className:\"language-python code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"# check the testing dataset columns and their datatypes\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"2\",children:[\"test_df\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"info\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"#\"}),(0,n.jsx)(e.th,{children:\"Column\"}),(0,n.jsx)(e.th,{children:\"Non-Null Count\"}),(0,n.jsx)(e.th,{children:\"Dtype\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"0\"}),(0,n.jsx)(e.td,{children:\"ID\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"object\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"1\"}),(0,n.jsx)(e.td,{children:\"PRG\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"2\"}),(0,n.jsx)(e.td,{children:\"PL\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"3\"}),(0,n.jsx)(e.td,{children:\"PR\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"4\"}),(0,n.jsx)(e.td,{children:\"SK\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"5\"}),(0,n.jsx)(e.td,{children:\"TS\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"6\"}),(0,n.jsx)(e.td,{children:\"M11\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"float64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"7\"}),(0,n.jsx)(e.td,{children:\"BD2\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"float64\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"8\"}),(0,n.jsx)(e.td,{children:\"Age\"}),(0,n.jsx)(e.td,{children:\"169 non-null\"}),(0,n.jsx)(e.td,{children:\"int64\"})]})]})]}),`\n`,(0,n.jsx)(e.p,{children:\"As we can see, there are no columns in either the training or testing dataset that have missing values, which means we won't need to deal with any null values during data cleaning.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Additionally, the data types for the columns in both datasets appear to be correct, with integer columns being represented as int64 and floating-point columns as float64.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Two columns, ID and Sepssis, are represented as object data type since they contain string values. However, ID is unnecessary and will be removed, while Sepssis will be encoded later on.\"}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsx)(e.code,{className:\"language-python code-highlight\",children:(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[\"train_df\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"describe\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),`T\n`]})})}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{}),(0,n.jsx)(e.th,{children:\"count\"}),(0,n.jsx)(e.th,{children:\"mean\"}),(0,n.jsx)(e.th,{children:\"std\"}),(0,n.jsx)(e.th,{children:\"min\"}),(0,n.jsx)(e.th,{children:\"25%\"}),(0,n.jsx)(e.th,{children:\"50%\"}),(0,n.jsx)(e.th,{children:\"75%\"}),(0,n.jsx)(e.th,{children:\"max\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"PRG\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"3.824708\"}),(0,n.jsx)(e.td,{children:\"3.362839\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"1.000\"}),(0,n.jsx)(e.td,{children:\"3.000\"}),(0,n.jsx)(e.td,{children:\"6.000\"}),(0,n.jsx)(e.td,{children:\"17.00\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"PL\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"120.153589\"}),(0,n.jsx)(e.td,{children:\"32.682364\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"99.000\"}),(0,n.jsx)(e.td,{children:\"116.000\"}),(0,n.jsx)(e.td,{children:\"140.000\"}),(0,n.jsx)(e.td,{children:\"198.00\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"PR\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"68.732888\"}),(0,n.jsx)(e.td,{children:\"19.335675\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"64.000\"}),(0,n.jsx)(e.td,{children:\"70.000\"}),(0,n.jsx)(e.td,{children:\"80.000\"}),(0,n.jsx)(e.td,{children:\"122.00\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SK\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"20.562604\"}),(0,n.jsx)(e.td,{children:\"16.017622\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"23.000\"}),(0,n.jsx)(e.td,{children:\"32.000\"}),(0,n.jsx)(e.td,{children:\"99.00\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"TS\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"79.460768\"}),(0,n.jsx)(e.td,{children:\"116.576176\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"36.000\"}),(0,n.jsx)(e.td,{children:\"123.500\"}),(0,n.jsx)(e.td,{children:\"846.00\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"M11\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"31.920033\"}),(0,n.jsx)(e.td,{children:\"8.008227\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"27.100\"}),(0,n.jsx)(e.td,{children:\"32.000\"}),(0,n.jsx)(e.td,{children:\"36.550\"}),(0,n.jsx)(e.td,{children:\"67.10\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"BD2\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"0.481187\"}),(0,n.jsx)(e.td,{children:\"0.337552\"}),(0,n.jsx)(e.td,{children:\"0.078\"}),(0,n.jsx)(e.td,{children:\"0.248\"}),(0,n.jsx)(e.td,{children:\"0.383\"}),(0,n.jsx)(e.td,{children:\"0.647\"}),(0,n.jsx)(e.td,{children:\"2.42\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Age\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"33.290484\"}),(0,n.jsx)(e.td,{children:\"11.828446\"}),(0,n.jsx)(e.td,{children:\"21.000\"}),(0,n.jsx)(e.td,{children:\"24.000\"}),(0,n.jsx)(e.td,{children:\"29.000\"}),(0,n.jsx)(e.td,{children:\"40.000\"}),(0,n.jsx)(e.td,{children:\"81.00\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Insurance\"}),(0,n.jsx)(e.td,{children:\"599.0\"}),(0,n.jsx)(e.td,{children:\"0.686144\"}),(0,n.jsx)(e.td,{children:\"0.464447\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"0.000\"}),(0,n.jsx)(e.td,{children:\"1.000\"}),(0,n.jsx)(e.td,{children:\"1.000\"}),(0,n.jsx)(e.td,{children:\"1.00\"})]})]})]}),`\n`,(0,n.jsx)(e.p,{children:\"Based on the summary of statistics provided, we can draw some conclusions about the columns and their values\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"There are 599 observations in each column, which indicates that there are no missing values in the dataset.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Most columns, the average and median values are similar, suggesting that their distribution is similar to that of a normal distribution.\"}),`\n`,(0,n.jsx)(e.li,{children:\"The Insurance columns contains nominal data and other columns contain either discrete or continuous data.\"}),`\n`,(0,n.jsx)(e.li,{children:`Blood Work Result-3 (TS) has a mean of 79.46 and a large standard deviation of 116.58. This attribute has a positively skewed distribution toward\nhigher number, with most patients having low results and a few patients having very high results.`}),`\n`,(0,n.jsx)(e.li,{children:`The patient ages range from 21 to 81 years, with a mean age of 33.29 and a standard deviation of 11.83. This indicates that the patient population is\nrelatively young, with most patients being in their 20s or 30s.`}),`\n`,(0,n.jsx)(e.li,{children:\"Most patients (68.6%) hold a valid insurance card, as indicated by the Insurance column.\"}),`\n`]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-python\",children:(0,n.jsxs)(e.code,{className:\"language-python code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"1\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"# visualize the value distribution of the dataframe\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"2\",children:[\"train_df\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"hist\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"figsize\",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"20\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"10\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line line-number\",line:\"3\",children:[\"plt\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"show\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsx)(e.p,{children:`The graph above confirms some observations made earlier about the distribution of the variables in the dataset. For instance, the histograms for the PL, PR,\nand M11 columns are roughly symmetric and resemble a normal distribution curve. This suggests that these variables are normally distributed.`}),`\n`,(0,n.jsx)(e.p,{children:`On the other hand, the histogram for the TS column shows a long right tail, indicating that the distribution is highly skewed to the right. This\ncorresponds to the high skewness value observed in the statistical summary. Similarly, the PRG, SK, BD2, and Age columns also exhibit some degree of\nskewness.`}),`\n`,(0,n.jsx)(e.p,{children:`It is important to note that skewed distributions can affect the performance of certain statistical analyses and machine learning models. Therefore, we\nmay need to consider normalizing or transforming these variables before applying certain techniques or models.`}),`\n`,(0,n.jsxs)(e.h2,{id:\"thats-all-for-now\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#thats-all-for-now\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"That's all for now\"]}),`\n`,(0,n.jsx)(e.p,{children:\"In part 1 of this series, we focused on retrieving the dataset and importing the necessary packages for data cleaning, exploratory data analysis (EDA), and machine learning. The dataset was described in terms of its data fields, and attributes/targets, and then loaded into the notebook.\"}),`\n`,(0,n.jsx)(e.p,{children:\"It is essential to note that while data retrieval is a crucial part of the machine learning workflow, it is only the beginning. The next steps are data cleaning and exploratory data analysis, which are crucial in preparing the dataset for machine learning.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Data cleaning is a process of identifying and addressing issues in the data that could affect the accuracy of the model. These issues include missing values, outliers, duplicates, and inconsistent data. In part 2 of this series, we will focus on data cleaning by identifying and addressing these issues.\"})]})}function w(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,Object.assign({},i,{children:(0,n.jsx)(h,i)})):h(i)}var v=w;return N(A);})();\n;return Component;"
  },
  "_id": "articles/data-modelling-using-scikit-learn.mdx",
  "_raw": {
    "sourceFilePath": "articles/data-modelling-using-scikit-learn.mdx",
    "sourceFileName": "data-modelling-using-scikit-learn.mdx",
    "sourceFileDir": "articles",
    "contentType": "mdx",
    "flattenedPath": "articles/data-modelling-using-scikit-learn"
  },
  "type": "Article",
  "url": "/articles/data-modelling-using-scikit-learn",
  "slug": "articles/data-modelling-using-scikit-learn",
  "readingTime": "13 min read",
  "wordCount": 2430
}